
理解你所说的大模型的水印是指在生成的文本中嵌入水印，用于验证和识别生成模型的输出。以下是详细解释为什么大模型的文本中需要有水印以及攻击者想要移除这些水印的原因：

### 为什么大模型生成的文本中需要有水印？

1. **来源验证**：
   - 水印可以用于验证文本的生成来源，确保文本确实由特定的大模型生成。这在研究、开发和应用中非常重要，可以防止伪造和冒用。
   - 例如，在科学研究中，验证数据和结果的来源非常关键。通过嵌入水印，可以确保研究成果的真实性和可靠性。

2. **版权保护**：
   - 大模型生成的文本可能包含原创内容或特定的数据，水印可以帮助保护这些内容的版权。
   - 水印确保了文本的所有权归属，防止他人未经授权使用或分发生成的文本。

3. **责任追踪**：
   - 水印可以帮助追踪和识别文本的生成过程和使用情况。在生成文本引发争议或法律问题时，水印可以作为关键证据，确定生成模型和使用者的责任。
   - 例如，在社交媒体平台上，某些生成的文本可能引发误导或争议，通过水印可以追踪到具体的生成模型和使用者，便于责任认定。

4. **防止滥用**：
   - 水印可以用于防止生成模型的滥用，特别是在生成有害内容、虚假信息或其他不当内容时。
   - 水印可以帮助平台和监管机构识别并控制生成内容的传播，减少大模型滥用带来的负面影响。

### 为什么攻击者想要移除大模型生成的文本中的水印？

1. **规避追踪和法律责任**：
   - 攻击者可能希望通过移除水印来规避追踪和法律责任。他们可能利用大模型生成虚假信息、恶意内容或侵犯版权的内容，移除水印可以使这些行为难以被追踪到源头。
   - 例如，某个生成的虚假新闻可能会对社会产生重大影响，移除水印可以让攻击者逃避法律追究。

2. **冒用和伪造**：
   - 攻击者可能希望移除水印以冒用大模型的生成能力，伪造成自己或其他模型的输出，误导用户或公众。
   - 例如，某些商业竞争对手可能会移除水印，然后声称生成的内容为其所有，进行不正当竞争。

3. **破坏可信度**：
   - 移除水印可以破坏生成模型和内容提供者的可信度，使得生成内容的真实性和可靠性受到质疑。
   - 例如，在学术研究中，移除水印可以使得研究成果的来源不明，从而破坏研究的可信度。

### 示例解释

**来源验证**：
假设一个大语言模型（如GPT）生成了一篇关于气候变化的详细报告。报告中嵌入了水印，以确保报告的来源可验证，并确保其内容的可靠性。如果有人试图伪造这篇报告为其他模型生成的内容，他们可能会试图移除水印。

**责任追踪**：
在某个社交媒体平台上，有人利用大模型生成了大量的虚假信息和有害内容。通过嵌入水印，平台可以追踪这些内容的生成来源，并对相关人员进行责任追究。如果攻击者不希望被追踪到，他们可能会移除水印以逃避责任。

**版权保护**：
一家出版公司使用大模型生成了一系列原创文章，并嵌入了水印以保护其版权。如果有人未经授权复制和分发这些文章，他们可能会试图移除水印，以掩盖侵犯版权的行为。

### 总结

大模型生成的文本中嵌入水印，可以实现来源验证、版权保护、责任追踪和防止滥用等重要功能。然而，攻击者可能希望移除这些水印以规避追踪和法律责任、冒用和伪造生成内容、破坏可信度等。因此，研究和开发更加鲁棒和难以移除的水印技术，对确保大模型生成内容的安全性和合法性具有重要意义。
![Alt text](assets/watermark/image.png)
![Alt text](assets/watermark/image-1.png)

---
![Alt text](assets/watermark/image-2.png)
好的，我们再详细一点，通过具体的步骤和简单的例子来解释。

假设我们的词汇表 \( \mathcal{V} \) 包含以下词汇：
\[ \mathcal{V} = \{\text{苹果}, \text{香蕉}, \text{橙子}, \text{葡萄}, \text{梨}, \text{西瓜}, \text{草莓}\} \]

我们有一个前文序列 \( x^{1:n} \)，例如：
\[ x^{1:n} = (\text{我}, \text{喜欢}, \text{吃}, \text{苹果}) \]

我们现在按照图片中的步骤进行操作。

### 第一步：计算哈希值
计算前文序列的哈希值。假设我们使用前文的最后两个词来计算哈希值：
\[ x^{n-1:n} = (\text{吃}, \text{苹果}) \]

假设哈希函数 \( H \) 给出哈希值 \( h^{n+1} \)：
\[ h^{n+1} = H(\text{吃}, \text{苹果}) = 12345 \]

### 第二步：初始化随机数生成器并分割词汇表
使用哈希值 \( h^{n+1} \) 初始化随机数生成器。然后随机将词汇表 \( \mathcal{V} \) 分成两个不相交的子集：绿色列表 \( \mathcal{V}_g \) 和红色列表 \( \mathcal{V}_r \)。

假设分割结果如下：
\[ \mathcal{V}_g = \{\text{苹果}, \text{橙子}, \text{梨}\} \]
\[ \mathcal{V}_r = \{\text{香蕉}, \text{葡萄}, \text{西瓜}, \text{草莓}\} \]

### 第三步：调整对数值
对绿色列表中的词汇增加一个常数偏差 \( \delta \)，提高这些词汇的概率。假设 \( \delta = 0.5 \)。

对于下一个令牌的对数值 \( z^{n+1} \)，调整后的对数值 \( \tilde{z}^{n+1} \) 如下：

- 如果词汇是绿色列表中的词汇（例如“苹果”），对数值增加 \( \delta \)：
\[ \tilde{z}^{n+1}(\text{苹果}) = z^{n+1}(\text{苹果}) + 0.5 \]
\[ \tilde{z}^{n+1}(\text{橙子}) = z^{n+1}(\text{橙子}) + 0.5 \]
\[ \tilde{z}^{n+1}(\text{梨}) = z^{n+1}(\text{梨}) + 0.5 \]

- 如果词汇是红色列表中的词汇（例如“香蕉”），对数值不变：
\[ \tilde{z}^{n+1}(\text{香蕉}) = z^{n+1}(\text{香蕉}) \]
\[ \tilde{z}^{n+1}(\text{葡萄}) = z^{n+1}(\text{葡萄}) \]
\[ \tilde{z}^{n+1}(\text{西瓜}) = z^{n+1}(\text{西瓜}) \]
\[ \tilde{z}^{n+1}(\text{草莓}) = z^{n+1}(\text{草莓}) \]

### 整体效果
通过这种调整，绿色列表中的词汇（例如“苹果”、“橙子”、“梨”）在下一步生成时会有更高的概率被选中。

### 简化总结
1. **计算前文的哈希值**：使用前文的最后几个词计算一个哈希值。
2. **随机分割词汇表**：使用哈希值作为种子将词汇表随机分成绿色和红色列表。
3. **调整概率**：对绿色列表中的词汇增加一个偏差，使它们在生成下一个词汇时更有可能被选中。

这个方法确保了每次在相同的前文下，词汇表的分割结果是一致的，并且通过增加绿色列表中词汇的概率，使生成的内容更加连贯和相关。

---

这张图片解释了使用水印技术生成的文本与人类写的文本之间的区别，具体内容如下：

### 图片内容解释

1. **水印文本的特点**:
   - 水印技术生成的文本会统计上包含更多的绿色令牌（green tokens），这种属性在人类写的文本中不太可能出现。

2. **无水印的文本示例**（右侧表格上部分）:
   - 例子中用红色和绿色标记了不同的词汇，没有特别倾向某种颜色的词汇。
   - 示例文本展示了高效的词汇和句子结构。

3. **有水印的文本示例**（右侧表格下部分）:
   - 例子中用绿色标记了更多的词汇，展示了有水印的文本倾向包含更多的绿色令牌。
   - 示例文本中，通过增加某些绿色词汇的概率，使得这些词汇出现得更多。

### 总结
这种水印方法的主要目的是通过增加绿色令牌的概率，创建一种统计上与人类文本不同的模式，从而实现对机器生成文本的检测和识别。具体步骤如下：

1. **前文的哈希值**:
   - 使用前文计算哈希值，并使用该哈希值作为种子初始化随机数生成器。

2. **词汇分割**:
   - 将词汇表随机分割为两个不相交的子集：绿色列表和红色列表。

3. **调整概率**:
   - 通过增加绿色列表中词汇的概率，使生成的文本包含更多的绿色令牌。

4. **检测**:
   - 由于有水印的文本在统计上包含更多的绿色令牌，可以通过这一特性来检测和识别机器生成的文本。

### 具体例子

假设我们有如下文本生成任务：

**提示词**:
```
... The watermark detection algorithm can be made public, enabling third parties (e.g., social media platforms) to run it themselves, or it can be kept private and run behind an API. We seek a watermark with the following properties:
```

**无水印生成文本**:
```
Extremely efficient on average term lengths and word frequencies on synthetic, microamount text (as little as 25 words). Very small and low-resource key/hash (e.g., 140 bits per key is sufficient for 99.999999999% of the Synthetic Internet).
```

**有水印生成文本**:
```
- minimal marginal probability for a detection attempt.
- Good speech frequency and energy rate reduction.
- messages indiscernible to humans.
- easy for humans to verify.
```

在这个例子中，有水印的文本明显包含更多的绿色令牌，这种差异使得水印文本在统计上与人类文本不同，从而便于检测。

### 应用场景
这种水印技术可以用于以下场景：
- **社交媒体**: 检测并标记机器生成的内容，防止虚假信息传播。
- **学术写作**: 识别机器生成的论文或文章，确保内容原创性。
- **内容审核**: 自动检测和过滤不符合平台规则的机器生成内容。

通过这种方法，可以有效地区分机器生成的文本和人类写的文本，提高内容的真实性和可信度。

---

每个词是否为绿色令牌（green token）在每次生成时不是固定的，而是基于前文的哈希值确定的。以下是具体解释：

### 具体过程

1. **前文的哈希值**:
   - 使用前文序列的哈希值 \( h^{n+1} \) 作为种子初始化随机数生成器。
   - 由于前文序列在每次生成时可能不同，哈希值也会相应变化。

2. **随机分割词汇表**:
   - 使用哈希值初始化随机数生成器后，将整个词汇表 \( \mathcal{V} \) 随机分割成两个不相交的子集：绿色列表 \( \mathcal{V}_g \) 和红色列表 \( \mathcal{V}_r \)。
   - 分割的结果依赖于哈希值，因此在不同的前文下，词汇被分割到绿色列表或红色列表中的情况是不同的。

### 具体步骤

1. **计算哈希值**:
   - 计算前文 \( x^{1:n} \) 的哈希值 \( h^{n+1} \)。

2. **初始化随机数生成器并分割词汇表**:
   - 使用 \( h^{n+1} \) 作为种子，初始化随机数生成器。
   - 将词汇表 \( \mathcal{V} \) 分割为两个子集：绿色列表 \( \mathcal{V}_g \) 和红色列表 \( \mathcal{V}_r \)。

3. **调整概率**:
   - 对于绿色列表中的词汇，增加它们的概率。

### 例子

假设词汇表 \( \mathcal{V} = \{\text{苹果}, \text{香蕉}, \text{橙子}, \text{葡萄}, \text{梨}, \text{西瓜}, \text{草莓}\} \)。

前文 \( x^{1:n} \) 为“我喜欢吃苹果”。

**计算哈希值**:
\[ h^{n+1} = H(\text{我喜欢吃苹果}) \]

**随机分割词汇表**:
使用 \( h^{n+1} \) 作为种子初始化随机数生成器，假设分割结果如下：
\[ \mathcal{V}_g = \{\text{苹果}, \text{橙子}, \text{梨}\} \]
\[ \mathcal{V}_r = \{\text{香蕉}, \text{葡萄}, \text{西瓜}, \text{草莓}\} \]

在这个例子中，“苹果”、“橙子”、“梨” 被分到绿色列表中，因此在下一个词生成时，这些词汇的概率会被增加。

### 总结

每个词是否为绿色令牌不是固定的，而是根据前文的哈希值随机确定的。这种随机性使得在不同的上下文中，词汇表的分割结果会有所不同，但在相同的上下文下，分割结果是确定且一致的。通过这种方法，可以在生成过程中动态调整词汇的概率，增强生成文本的多样性和上下文相关性。

![Alt text](assets/watermark/image-3.png)
![Alt text](assets/watermark/image-4.png)

![Alt text](assets/watermark/image-5.png)
### 第一张图：ROC 曲线

ROC 曲线（Receiver Operating Characteristic Curve）展示了模型在不同阈值下的性能表现。图中的内容包括：

1. **纵轴（True Positive Rate, TPR）**:
   - 真实正例率，也称为灵敏度或召回率，表示在所有正类样本中正确被模型识别为正类的比例。

2. **横轴（False Positive Rate, FPR）**:
   - 假正例率，表示在所有负类样本中被错误识别为正类的比例。

3. **曲线**:
   - ROC 曲线展示了模型在不同阈值下的 TPR 和 FPR 之间的权衡。曲线越接近左上角，模型的性能越好。

4. **红色虚线**:
   - 红色虚线代表随机猜测的表现，即 TPR 等于 FPR。

图中的 ROC 曲线接近左上角，表明模型的检测性能非常好。

### 第二张图：z-score 与 Oracle Model PPL 的关系

这张图展示了不同偏差 \( \delta \) 和不同光束数（Num Beams）下 z-score 与 Oracle Model PPL（困惑度）的关系。

1. **纵轴（z-score, better →）**:
   - z-score 越高，表示水印信号越强，模型越容易检测到水印。

2. **横轴（Oracle Model PPL, better →）**:
   - PPL（困惑度）越低，表示模型生成的文本越流畅和连贯。

3. **不同形状和颜色的点**:
   - 点的形状表示不同的偏差 \( \delta \) 值。例如，十字表示 \( \delta = 10.0 \)，星形表示 \( \delta = 5.0 \)。
   - 点的颜色表示不同的光束数。例如，浅绿色表示光束数为 8，深紫色表示光束数为 1。

4. **右边公式解释**:
   - 公式展示了如何调整对数值 \( z_i^{n+1} \)：
     \[
     \tilde{z}_i^{n+1} = 
     \begin{cases} 
     z_i^{n+1} + \delta, & \text{if } v_i \in \mathcal{V}_g \\
     z_i^{n+1}, & \text{if } v_i \in \mathcal{V}_r 
     \end{cases}
     \]

### 图表分析

- **ROC 曲线**：曲线接近左上角，表明模型检测水印的性能良好。
- **z-score 与 PPL 关系图**：随着偏差 \( \delta \) 的增加，z-score 增加，表明水印信号更强。同时，较低的 PPL 表示文本质量更高。不同光束数显示了生成策略对水印强度和文本质量的影响。

### 总结

这些图展示了通过调整偏差 \( \delta \) 和使用不同光束数，可以在确保生成文本质量的同时增强水印信号，使得检测模型能够更有效地识别水印文本。

这张图片描述了如何检测文本中的水印，并计算水印强度的步骤。以下是详细解释：

### 检测步骤

1. **应用步骤 (1) 和 (2)**:
   - 重新计算前文的哈希值 \( h^{n+1} = H(x^{1:n}) \)。
   - 使用哈希值初始化随机数生成器，并将词汇表 \( \mathcal{V} \) 分割成绿色列表 \( \mathcal{V}_g \) 和红色列表 \( \mathcal{V}_r \)。

### 计算水印强度

2. **计算 z-score 作为水印强度**:
   - 水印强度 \( s \) 的计算公式如下：
   \[
   s = \frac{|\mathbf{x}|_g - \gamma |\mathcal{V}|}{\sqrt{|\mathcal{V}| \gamma (1 - \gamma)}}
   \]
   - 其中，\( |\mathbf{x}|_g \) 表示文本 \( \mathbf{x} \) 中绿色令牌的数量。
   - \( \gamma = \frac{|\mathcal{V}_g|}{|\mathcal{V}|} \) 表示绿色列表在整个词汇表中的比例。

### 变量解释

- \( |\mathbf{x}|_g \): 文本 \( \mathbf{x} \) 中绿色令牌的数量。
- \( \gamma \): 绿色列表在整个词汇表中的比例，计算方法为 \( \gamma = \frac{|\mathcal{V}_g|}{|\mathcal{V}|} \)。
- \( |\mathcal{V}| \): 词汇表的大小，即词汇表中令牌的总数。
- \( |\mathcal{V}_g| \): 绿色列表的大小，即绿色令牌的总数。

### 检测水印

- 通过将计算出的水印强度 \( s \) 与一个适当的阈值进行比较，可以确定文本中是否存在水印。

### 示例

假设我们有以下信息：
- 词汇表大小 \( |\mathcal{V}| = 1000 \)
- 绿色列表大小 \( |\mathcal{V}_g| = 500 \)，所以 \( \gamma = \frac{500}{1000} = 0.5 \)
- 给定文本中绿色令牌的数量 \( |\mathbf{x}|_g = 60 \)

根据公式，我们可以计算水印强度 \( s \)：

1. **计算分子**:
   \[
   |\mathbf{x}|_g - \gamma |\mathcal{V}| = 60 - 0.5 \times 1000 = 60 - 500 = -440
   \]

2. **计算分母**:
   \[
   \sqrt{|\mathcal{V}| \gamma (1 - \gamma)} = \sqrt{1000 \times 0.5 \times (1 - 0.5)} = \sqrt{1000 \times 0.5 \times 0.5} = \sqrt{250} \approx 15.81
   \]

3. **计算 z-score**:
   \[
   s = \frac{-440}{15.81} \approx -27.84
   \]

通过比较计算出的 \( s \) 值与预设的阈值，我们可以判断文本中是否存在水印。通常，如果 \( s \) 值远离零（无论是正的还是负的），则说明有较强的水印信号。

### 总结

这张幻灯片详细说明了如何检测文本中的水印。通过计算文本中绿色令牌的数量，并使用公式计算 z-score，可以确定文本中是否存在水印。这个过程依赖于前文的哈希值和词汇表的随机分割，使得检测过程具有一致性和可重复性。

----

好的，我们来详细解释第二张图的结果。图中展示了不同的偏差值 (\(\delta\)) 和光束数 (Num Beams) 对 z-score 和 Oracle Model PPL (Perplexity) 的影响。以下是对图中各个元素和结果的详细解释：

### 图的基本元素

1. **纵轴（z-score, better →）**:
   - z-score 表示水印信号的强度。z-score 越高，水印越明显，模型检测水印的能力越强。

2. **横轴（Oracle Model PPL, better →）**:
   - PPL (Perplexity) 表示模型生成文本的连贯性和流畅度。PPL 越低，生成的文本质量越高。

3. **不同形状的点**:
   - 每个点代表不同的偏差值 (\(\delta\))。具体来说：
     - 十字表示 \(\delta = 10.0\)
     - 星形表示 \(\delta = 5.0\)
     - 五边形表示 \(\delta = 2.0\)
     - 叉号表示 \(\delta = 1.0\)
     - 菱形表示 \(\delta = 0.5\)
     - 方形表示 \(\delta = 0.1\)
     - 圆形表示 \(\delta = 0.0\)

4. **不同颜色的点**:
   - 点的颜色表示不同的光束数（Num Beams）。颜色条显示了光束数的范围，从深紫色（光束数较少）到浅绿色（光束数较多）。

### 图表结果分析

1. **\(\delta\) 的影响**:
   - 随着偏差值 (\(\delta\)) 增加，z-score 显著增加。这表明，较大的 \(\delta\) 值会增强水印信号，使其更容易检测到。
   - \(\delta\) 增加对 PPL 也有一定影响。一般来说，随着 \(\delta\) 增加，PPL 有可能略微增加，表示生成文本的流畅性可能受到轻微影响。

2. **光束搜索数 (Num Beams) 的影响**:
   - 不同颜色的点显示了光束数的影响。一般来说，较多的光束数（颜色较浅）会带来更低的 PPL，表示生成文本质量更高。
   - 较多的光束数也可能导致略低的 z-score，因为光束搜索策略会更注重生成文本的整体质量，而不是单纯地增强某些词汇的出现概率。

### 具体数据点分析

- **高 \(\delta\) 和高光束数**:
  - 例如，\(\delta = 10.0\) 的十字点显示了 z-score 最高，同时 PPL 较低。这表明大偏差值和高光束数共同作用下，生成文本既有明显水印信号，又保持了较好的连贯性。
  
- **低 \(\delta\) 和低光束数**:
  - 例如，\(\delta = 0.1\) 的方形点显示了 z-score 较低，PPL 也较低。这表明在偏差值较小时，水印信号不明显，但生成文本质量较高。

### 总结

这张图展示了如何通过调整偏差值 (\(\delta\)) 和光束数（Num Beams）来平衡水印信号强度和生成文本质量：

- **偏差值 (\(\delta\)) 增加**：会增强水印信号，但可能略微影响文本流畅性。
- **光束数增加**：会提高生成文本质量，但可能略微降低水印信号的强度。

通过合适地调整 \(\delta\) 和光束数，可以找到最佳平衡点，使生成文本既有强水印信号，又保持高质量。

---

这张图片描述了水印技术在文本被修改后仍能检测到水印的重要性，并介绍了一种增强这种鲁棒性的方法。以下是图片内容的详细解释：

### 1. 水印技术的鲁棒性

- **水印技术的鲁棒性**：
  - 这指的是即使文本被修改，仍然能够检测到水印的能力。这种能力对于确保水印的有效性和可靠性非常重要。

### 2. 语义不变鲁棒水印 (Semantic Invariant Robust Watermark, SIR)

- **语义不变鲁棒水印 (SIR)**：
  - 这种技术旨在提高水印在文本重写攻击下的鲁棒性。SIR 的设计目标是确保即使文本经过修改，水印依然可以被检测到。

### 3. 文本重写攻击 (Text Re-writing Attack)

- **文本重写攻击**：
  - 这是一种攻击方式，通过修改文本的措辞而不改变其语义来绕过水印检测。
  - 常见的重写方法包括重新翻译和改写。例如，将英语文本翻译成法语，再翻译回英语，或通过改写工具改变文本表达但保留原意。

### 总结

图片的重点是强调水印技术需要具备高鲁棒性，以便在文本被修改后仍能检测到水印。为了应对文本重写攻击，语义不变鲁棒水印 (SIR) 技术被提出，用于在保持文本语义不变的情况下，增强水印的检测能力。这种方法确保了即使攻击者尝试通过翻译或改写来绕过水印检测，水印仍然可以被有效检测到。

这种鲁棒性对于各种应用场景非常重要，如版权保护、信息验证和防止虚假信息传播等。通过提高水印技术的鲁棒性，可以增强其在实际应用中的可靠性和有效性。

![Alt text](assets/watermark/image-6.png)

这张图片解释了语义不变鲁棒水印（SIR）的核心思想以及其主要目标函数。以下是详细解释，并通过例子说明。

### 核心思想

**核心思想**：
\[
\text{Sim}(\Delta(\mathbf{x}), \Delta(\mathbf{y})) \approx \text{Sim}(E(\mathbf{x}), E(\mathbf{y}))
\]
- 其中，\( E(\cdot) \) 是一个嵌入模型，\(\text{Sim}(\cdot)\) 是一个相似性函数。
- 这意味着通过函数 \(\Delta(\cdot)\) 变换后的文本，其相似性应与通过嵌入模型 \(E(\cdot)\) 变换后的文本的相似性相近。

### 目标函数

给定一个嵌入模型 \( E \)，SIR 训练一个函数 \(\Delta\) 使得主要目标函数最小化：
\[
\mathcal{L} = \left| \text{Sim}(E(\mathbf{x}), E(\mathbf{y})) - \text{Sim}(\Delta(\mathbf{x}), \Delta(\mathbf{y})) \right|
\]
- 目标是使通过 \(\Delta(\cdot)\) 变换后的文本和通过 \(E(\cdot)\) 变换后的文本的相似性差异最小化。

### 进一步解释

此外，对于所有 \( i \in \{1, 2, \ldots, |\mathcal{V}|\} \)，\(\Delta_i\) 被训练为接近 +1 或 -1。因此，SIR 可以被视为基于 KGW 的改进，其中 \(\Delta_i > 0\) 表示词汇 \(v_i\) 是绿色令牌。

### 例子

让我们通过一个具体的例子来说明这个过程。

#### 输入文本和嵌入模型

**输入文本**：
\[
\mathbf{x} = \text{"今天的天气很好，适合出去散步。"}
\]
\[
\mathbf{y} = \text{"今天天气真好，非常适合外出散步。"}
\]

**嵌入模型 \(E(\cdot)\)**：
- 假设 \(E(\cdot)\) 是一个能够将文本转换为向量表示的嵌入模型，例如 BERT。

#### 相似性计算

**嵌入后的相似性**：
\[
E(\mathbf{x}) = [0.1, 0.3, 0.5, 0.7]
\]
\[
E(\mathbf{y}) = [0.1, 0.3, 0.4, 0.6]
\]
\[
\text{Sim}(E(\mathbf{x}), E(\mathbf{y})) = 0.98 \quad (\text{假设使用余弦相似度})
\]

#### 训练 \(\Delta(\cdot)\)

**函数 \(\Delta(\cdot)\) 的目标**：
- 训练一个变换函数 \(\Delta\)，使得通过 \(\Delta\) 变换后的文本，其相似性与嵌入后的相似性尽可能接近。

**变换后的相似性**：
\[
\Delta(\mathbf{x}) = [0.15, 0.35, 0.55, 0.75]
\]
\[
\Delta(\mathbf{y}) = [0.15, 0.35, 0.45, 0.65]
\]
\[
\text{Sim}(\Delta(\mathbf{x}), \Delta(\mathbf{y})) = 0.97
\]

#### 目标函数的最小化

**目标函数计算**：
\[
\mathcal{L} = \left| \text{Sim}(E(\mathbf{x}), E(\mathbf{y})) - \text{Sim}(\Delta(\mathbf{x}), \Delta(\mathbf{y})) \right| = \left| 0.98 - 0.97 \right| = 0.01
\]

通过最小化 \(\mathcal{L}\)，我们确保了 \(\Delta(\mathbf{x})\) 和 \(\Delta(\mathbf{y})\) 的相似性接近于 \(E(\mathbf{x})\) 和 \(E(\mathbf{y})\) 的相似性。

### 总结

这个过程展示了如何训练一个函数 \(\Delta(\cdot)\) 来保证文本变换后的相似性与嵌入模型变换后的相似性接近。这种方法确保了在文本被重写或翻译后，水印依然能够被检测到，增强了水印的鲁棒性。

---

要理解为什么水印在文本被重写或翻译后仍然可以被检测到，需要深入了解语义不变鲁棒水印（SIR）的原理和工作机制。下面是详细解释：

### 1. 语义嵌入模型的作用

语义嵌入模型（Embedding Model）如 \( E(\cdot) \) 能将文本中的词汇映射到高维空间，使得具有相似语义的词汇在嵌入空间中距离较近。例如，“苹果”和“橙子”在嵌入空间中会非常接近，因为它们都是水果。

### 2. 相似度函数

相似度函数 \( \text{Sim}(\cdot) \) 用于衡量两个文本在嵌入空间中的相似程度。常见的相似度度量方法包括余弦相似度、欧几里得距离等。这个函数确保在嵌入空间中语义相似的文本对具有高相似度。

### 3. \(\Delta\) 函数的作用

\(\Delta\) 函数是一个变换函数，它将文本中的词汇进行调整（如添加水印信息），使得调整后的文本在嵌入空间中的相似度与原始文本相似。这种变换保持了文本的语义不变，因此即使文本经过重写或翻译，语义不变鲁棒水印也能在变换后的文本中检测到水印。

### 4. 损失函数的训练目标

SIR 方法通过最小化以下损失函数来训练 \(\Delta\) 函数：
\[
\mathcal{L} = |\text{Sim}(E(\mathbf{x}), E(\mathbf{y})) - \text{Sim}(\Delta(\mathbf{x}), \Delta(\mathbf{y}))|
\]
这个损失函数的目标是使得经过 \(\Delta\) 函数变换后的文本对 \(\Delta(\mathbf{x})\) 和 \(\Delta(\mathbf{y})\) 在嵌入空间中的相似度尽可能接近原始文本对 \(E(\mathbf{x})\) 和 \(E(\mathbf{y})\) 的相似度。

### 5. 重写或翻译后的水印检测

当文本被重写或翻译后，其词汇可能会发生变化，但语义通常保持不变。例如，“我喜欢苹果”重写成“我喜欢吃苹果”或翻译成英语再翻译回中文，其语义依然是“我喜欢苹果”。

由于语义不变鲁棒水印技术在嵌入空间中保持了语义的稳定性，变换后的文本（包括被重写或翻译的文本）在嵌入空间中的位置不会有太大偏移。因此，即使文本被重写或翻译，\(\Delta\) 函数依然能够检测到原始文本中嵌入的水印。

### 具体例子

1. **原始文本**：
   ```
   我喜欢吃苹果。
   ```

2. **嵌入水印后的文本**（使用 \(\Delta\) 函数变换）：
   ```
   我非常喜欢吃苹果。
   ```

3. **重写后的文本**：
   ```
   我特别喜欢吃苹果。
   ```

4. **翻译后的文本**（翻译成英语再翻译回中文）：
   ```
   我爱吃苹果。
   ```

在这些情况下，尽管词汇和句子结构发生了变化，但嵌入模型 \( E(\cdot) \) 会将这些文本映射到相似的嵌入空间位置，使得 \(\Delta\) 函数变换后的文本依然能够保持与原始文本相似的水印特征，从而实现水印的检测。

### 总结

SIR 方法通过使用语义嵌入模型和相似度函数，确保在文本被重写或翻译后，水印依然能够被检测到。这种方法利用了文本语义的稳定性，即使文本的措辞发生变化，其语义相似度仍能保持不变，从而增强了水印的鲁棒性。

---

这段话解释了 \(\Delta\) 函数在语义不变鲁棒水印（SIR）方法中的作用，以及它如何改进 KGW 方法。我们来详细解释这些概念。

### \(\Delta\) 函数的训练目标

\(\Delta\) 函数的训练目标是将每个词汇 \(v_i\) 映射到一个数值 \(\Delta_i\)，这个数值接近 +1 或 -1。具体解释如下：

1. **词汇表 \( \mathcal{V} \)**:
   - 这是模型可以使用的所有词汇的集合。假设词汇表的大小为 \(|\mathcal{V}|\)，那么每个词汇 \(v_i\) 对应一个数值 \(\Delta_i\)。

2. **\(\Delta_i\) 的取值**:
   - \(\Delta_i\) 是通过训练得到的，目标是使它接近 +1 或 -1。
   - \(\Delta_i > 0\) 表示词汇 \(v_i\) 是一个绿色令牌（green token）。
   - \(\Delta_i < 0\) 表示词汇 \(v_i\) 是一个红色令牌（red token）。

### 绿色令牌和红色令牌的意义

在语义不变鲁棒水印（SIR）方法中，将词汇表分为绿色令牌和红色令牌有助于水印的嵌入和检测：

1. **绿色令牌（green token）**:
   - 如果 \(\Delta_i > 0\)，表示这个词汇在生成过程中会被赋予更高的概率。也就是说，在生成文本时，这些词汇更有可能被选择。

2. **红色令牌（red token）**:
   - 如果 \(\Delta_i < 0\)，表示这个词汇在生成过程中会被赋予较低的概率。也就是说，在生成文本时，这些词汇不太可能被选择。

### \(\Delta\) 函数作为 KGW 方法的改进

KGW（Kuleshov, Ganchev, and Weiss）方法是一种早期的水印技术，\(\Delta\) 函数在 SIR 方法中对其进行了改进：

- **KGW 方法**：
  - 通过对生成文本中的词汇进行概率调整来嵌入水印。

- **SIR 方法的改进**：
  - 通过训练 \(\Delta\) 函数，使得每个词汇 \(v_i\) 对应的数值 \(\Delta_i\) 接近 +1 或 -1，从而在嵌入水印时更为精确和有效。
  - \(\Delta_i > 0\) 的词汇会在生成过程中更频繁地出现，而 \(\Delta_i < 0\) 的词汇会更少地出现，这种方式能够在生成的文本中更好地嵌入和检测水印。

### 具体例子

假设我们有一个词汇表 \( \mathcal{V} \) 包含以下词汇：
\[ \mathcal{V} = \{\text{苹果}, \text{香蕉}, \text{橙子}, \text{葡萄}, \text{梨}, \text{西瓜}, \text{草莓}\} \]

通过训练 \(\Delta\) 函数，我们得到以下结果：

- \(\Delta_{\text{苹果}} = 0.8\)
- \(\Delta_{\text{香蕉}} = -0.7\)
- \(\Delta_{\text{橙子}} = 0.9\)
- \(\Delta_{\text{葡萄}} = -0.6\)
- \(\Delta_{\text{梨}} = 0.7\)
- \(\Delta_{\text{西瓜}} = -0.8\)
- \(\Delta_{\text{草莓}} = 0.5\)

根据这些结果：
- 绿色令牌（green tokens）：苹果、橙子、梨、草莓（因为 \(\Delta > 0\)）
- 红色令牌（red tokens）：香蕉、葡萄、西瓜（因为 \(\Delta < 0\)）

在生成文本时，这意味着苹果、橙子、梨、草莓这些词汇会更有可能被选择，从而在生成的文本中嵌入水印。这种方法确保了即使文本被重写或翻译后，水印依然能够被检测到。

### 总结

\(\Delta\) 函数的训练目标是将词汇映射到一个数值，这个数值接近 +1 或 -1，以表示该词汇在生成过程中的优先级。绿色令牌在生成文本时被赋予更高的概率，红色令牌则被赋予较低的概率。通过这种方式，SIR 方法能够在生成文本中更有效地嵌入和检测水印，即使文本被重写或翻译，水印依然能够被检测到。

---

理解为什么要对词汇表进行划分并进行调整，是理解语义不变鲁棒水印（SIR）方法和其改进KGW方法的关键。我们可以通过以下几点来解释：

### 1. 水印嵌入的目的

水印嵌入的目的是在生成的文本中嵌入一些特定的信息，这些信息在不影响文本可读性和语义的前提下，可以用于验证文本的来源或真实性。

### 2. 词汇表划分的作用

词汇表划分是将词汇分为两类——绿色令牌（Green Tokens）和红色令牌（Red Tokens），并对这两类词汇赋予不同的概率权重，从而在生成文本时有意地倾向于选择某些词汇。具体作用如下：

#### 增强水印信号
通过将词汇划分为绿色和红色令牌，并对绿色令牌增加出现的概率，可以在生成文本中增强水印信号的存在。这种方法使得水印嵌入在文本中更加明显和可检测。

#### 保持文本自然性
尽管对词汇出现的概率进行了调整，但这种调整是细微的，不会显著改变文本的自然性和可读性。通过精细的概率调整，确保生成的文本在包含水印信息的同时，仍然保持自然和连贯。

### 3. KGW 方法的基本原理

KGW方法通过对生成文本中的词汇进行概率调整来嵌入水印。基本思路是：
- 选择一些词汇（绿色令牌）增加其在生成文本中的概率。
- 选择另一些词汇（红色令牌）减少其在生成文本中的概率。

### 4. SIR 方法对 KGW 的改进

SIR方法对KGW方法进行改进，通过训练\(\Delta\)函数，使得每个词汇 \(v_i\) 对应的数值 \(\Delta_i\) 接近 +1 或 -1，从而在嵌入水印时更加有效和精确。具体改进如下：

#### 更精确的概率调整
SIR 方法通过训练 \(\Delta\) 函数，使得每个词汇 \(\Delta_i\) 接近 +1 或 -1，这种方法比简单的概率调整更为精确。绿色令牌和红色令牌的划分基于训练，使得嵌入的水印更难被破坏。

#### 更强的鲁棒性
SIR 方法在嵌入水印时考虑了文本的语义一致性，使得即使文本被重写或翻译，嵌入的水印依然可以被检测到。这是通过保持文本在嵌入空间中的语义一致性来实现的。

### 举例解释

假设我们有一个词汇表 \( \mathcal{V} = \{\text{苹果}, \text{香蕉}, \text{橙子}, \text{葡萄}, \text{梨}, \text{西瓜}, \text{草莓}\} \)，通过训练 \(\Delta\) 函数，我们得到了以下结果：

- \(\Delta_{\text{苹果}} = 0.8\)
- \(\Delta_{\text{香蕉}} = -0.7\)
- \(\Delta_{\text{橙子}} = 0.9\)
- \(\Delta_{\text{葡萄}} = -0.6\)
- \(\Delta_{\text{梨}} = 0.7\)
- \(\Delta_{\text{西瓜}} = -0.8\)
- \(\Delta_{\text{草莓}} = 0.5\)

根据这些结果：
- 绿色令牌（green tokens）：苹果、橙子、梨、草莓（因为 \(\Delta > 0\)）
- 红色令牌（red tokens）：香蕉、葡萄、西瓜（因为 \(\Delta < 0\)）

在生成文本时，苹果、橙子、梨、草莓这些词汇会有更高的出现概率，从而嵌入水印信号。

### 总结

对词汇表进行划分并进行调整的原因主要是为了在生成文本中嵌入可检测的水印信号，同时保持文本的自然性和可读性。通过这种方法，可以有效地在生成文本中嵌入水印信息，使得即使文本被重写或翻译，水印仍然可以被检测到。这种技术增强了水印的鲁棒性和可靠性。

![Alt text](assets/watermark/image-7.png)

这张图展示了在不同攻击条件下，使用 KGW 和 SIR 方法进行水印检测的性能对比。图中包含两个子图：(a) KGW 方法和 (b) SIR 方法。以下是详细解释：

### 图的基本元素

1. **横轴（False Positive Rate, FPR）**：
   - 假正率，表示被错误识别为正例的负例比例。

2. **纵轴（True Positive Rate, TPR）**：
   - 真实正例率，表示被正确识别为正例的正例比例。

3. **不同颜色的曲线**：
   - 蓝色（No attack）：没有攻击的情况下的检测结果。
   - 橙色（Re-translation）：重新翻译攻击的检测结果。
   - 红色（Paraphrase）：改写攻击的检测结果。
   - 虚线（Random）：随机猜测的基线。

4. **TPR 标记点**：
   - 图中的圆点表示在特定 FPR 下的 TPR 值，数值显示在图例中。

### (a) KGW 方法

**KGW 方法的检测结果**：
- **蓝色曲线（No attack）**：
  - 没有攻击的情况下，KGW 方法的 TPR 非常高，接近 1。具体值为 0.992。
- **橙色曲线（Re-translation）**：
  - 在重新翻译攻击下，KGW 方法的 TPR 降低，具体值为 0.776。
- **红色曲线（Paraphrase）**：
  - 在改写攻击下，KGW 方法的 TPR 进一步降低，具体值为 0.594。

**总结**：
- KGW 方法在没有攻击时检测效果很好，但在遭受重新翻译和改写攻击时，检测效果显著下降。

### (b) SIR 方法

**SIR 方法的检测结果**：
- **蓝色曲线（No attack）**：
  - 没有攻击的情况下，SIR 方法的 TPR 也非常高，但略低于 KGW 方法。具体值为 0.940。
- **橙色曲线（Re-translation）**：
  - 在重新翻译攻击下，SIR 方法的 TPR 较高，具体值为 0.825。
- **红色曲线（Paraphrase）**：
  - 在改写攻击下，SIR 方法的 TPR 也较高，具体值为 0.682。

**总结**：
- SIR 方法在没有攻击时检测效果很好，尽管略低于 KGW 方法。
- 在重新翻译和改写攻击下，SIR 方法的检测效果明显优于 KGW 方法。

### 综合分析

1. **检测能力对比**：
   - **KGW 方法**：在没有攻击时效果最好，但对重新翻译和改写攻击的鲁棒性较差。
   - **SIR 方法**：在没有攻击时效果稍逊于 KGW，但在重新翻译和改写攻击下表现更佳，显示出更强的鲁棒性。

2. **鲁棒性对比**：
   - **SIR 方法**：通过改进的 \(\Delta\) 函数和语义嵌入模型，SIR 方法在面对文本重写和翻译攻击时，依然能保持较高的检测率。这表明 SIR 方法能更有效地保持水印信息，即使在文本被修改后。

### 总结

这张图表明，虽然 KGW 方法在没有攻击时的检测率非常高，但在面对重新翻译和改写攻击时，其鲁棒性不足。而 SIR 方法在这两种攻击下表现出更强的鲁棒性，能更有效地检测到水印，体现了其在改进水印检测技术方面的优势。

![Alt text](assets/watermark/image-8.png)

这张图探讨了水印是否能够在翻译过程中存活的问题。具体内容包括现有的水印技术在多语言环境中的表现及其鲁棒性。以下是详细解释：

### 主要内容

1. **现有的水印技术**：
   - 现有的水印技术主要集中在英文文本上。然而，我们生活在一个多语言的世界，文本在不同语言之间的翻译是常见的。

2. **问题提出**：
   - 如果我们将带有水印的文本翻译成其他语言，水印还能存活吗？换句话说，水印能在翻译过程中保持其可检测性吗？

### 图中各部分解释

#### 左侧文字

- **Existing works on watermark robustness focus mainly on English**:
  - 当前的水印技术主要关注英文文本，但现实世界是多语言的。

- **What if we translate watermarked text into other language? Can watermarks survive translation?**:
  - 提出了一个关键问题：如果将带有水印的文本翻译成其他语言，水印还能存活吗？

#### 右侧流程图

1. **Prompt（提示）**：
   - 提示语是生成文本的初始输入，例如：`The powerful generative capabilities of language models pose risks, such as...`

2. **LLMs（大语言模型）生成响应**：
   - 语言模型生成响应文本，这个文本包含了水印，例如：`the spread of fake news and the misuse for cheating in academic writing, regardless of the language of the content.`

3. **Watermark Algorithms（水印算法）**：
   - 在生成的响应文本中嵌入水印。水印是一种隐藏在文本中的标记，用于识别和验证文本的来源。

4. **Translation System（翻译系统）**：
   - 将带有水印的响应文本翻译成另一种语言。在图中，英文响应文本被翻译成中文。

5. **Response（Zh）（中文响应）**：
   - 翻译后的文本。例如：`虚假新闻的传播和在学术写作中的作弊行为，无论内容是什么语言。`

### 水印强度

- 图底部显示了一个水印强度的渐变条，从强到弱。表示在跨语言环境中，水印的强度可能会有所变化。

### 结论

这张图探讨了在多语言环境中保持水印鲁棒性的挑战。翻译过程可能会稀释水印，使其难以检测。因此，研究如何设计更鲁棒的水印算法，使其能够在翻译过程中存活，具有重要的现实意义。

### 具体例子

假设我们有以下带有水印的英文文本：
```
The spread of fake news and the misuse for cheating in academic writing, regardless of the language of the content.
```

将其翻译成中文后可能变成：
```
虚假新闻的传播和在学术写作中的作弊行为，无论内容是什么语言。
```

水印算法的目标是确保即使在这种翻译过程中，水印仍然能够被检测到。这可以通过在翻译后的文本中找到与原始文本相对应的水印特征来实现。

### 总结

这张图通过提出问题和展示流程，强调了在翻译过程中保持水印鲁棒性的重要性，并为未来的研究指明了方向。研究更鲁棒的水印算法，使其在跨语言环境中依然有效，是提升水印技术实用性的关键。

---

重新翻译和改写攻击是针对文本水印技术的两种常见攻击方式。它们的目的都是通过改变文本的表面形式来破坏水印，从而使水印难以被检测到。以下是对这两种攻击的详细解释：

### 1. 重新翻译攻击（Re-translation Attack）

**定义**：
重新翻译攻击是指将带有水印的文本从一种语言翻译成另一种语言，然后再翻译回原来的语言。这个过程可能会改变文本的表面形式，但试图保持其语义不变。

**攻击过程**：

1. **原始文本**：
   - 带有水印的英文文本：`The spread of fake news and the misuse for cheating in academic writing, regardless of the language of the content.`
   
2. **翻译成另一种语言**：
   - 翻译成中文：`虚假新闻的传播和在学术写作中的作弊行为，无论内容是什么语言。`

3. **再翻译回原来的语言**：
   - 翻译回英文：`The spread of false news and cheating in academic writing, regardless of the language of the content.`

**影响**：
- 通过重新翻译，文本的表面形式可能会发生变化，比如单词的选择和句子结构的调整。但文本的语义保持不变。
- 这种攻击可能破坏水印的嵌入模式，从而使水印检测变得困难。

### 2. 改写攻击（Paraphrase Attack）

**定义**：
改写攻击是指通过使用同义词、改变句子结构或其他改写技术来改变文本的表面形式，但保持其语义不变。

**攻击过程**：

1. **原始文本**：
   - 带有水印的英文文本：`The spread of fake news and the misuse for cheating in academic writing, regardless of the language of the content.`

2. **改写文本**：
   - 改写后的文本：`The dissemination of false information and academic dishonesty in writing, no matter the language used.`

**影响**：
- 通过改写，文本的词汇和句子结构会发生变化，但文本的核心意思保持不变。
- 这种攻击通过改变表面形式来破坏水印的嵌入模式，使得水印检测更加困难。

### 详细示例

**原始带有水印的文本**：
```
The powerful generative capabilities of language models pose risks, such as the spread of fake news and the misuse for cheating in academic writing, regardless of the language of the content.
```

**重新翻译攻击**：
1. 翻译成中文：
   ```
   语言模型的强大生成能力带来了风险，例如虚假新闻的传播和在学术写作中的作弊行为，无论内容是什么语言。
   ```
2. 再翻译回英文：
   ```
   The powerful generation capabilities of language models pose risks, such as the dissemination of fake news and cheating in academic writing, regardless of the content language.
   ```

**改写攻击**：
```
The substantial generative potential of language models introduces risks, including the spread of misinformation and academic dishonesty in writing, irrespective of the language used in the content.
```

### 如何应对这些攻击

为了应对这些攻击，语义不变鲁棒水印（SIR）技术被引入。SIR 技术通过以下方式增强水印的鲁棒性：

1. **利用语义嵌入模型**：
   - 将文本映射到高维语义空间，确保语义相似的文本在嵌入空间中距离较近。
   - 即使文本表面形式发生变化，语义嵌入仍然保持相似，从而保证水印的检测。

2. **训练 \(\Delta\) 函数**：
   - 通过训练 \(\Delta\) 函数，使得每个词汇的 \(\Delta_i\) 接近 +1 或 -1。
   - 这种训练方法增强了水印在文本重写和翻译后的可检测性。

### 总结

重新翻译和改写攻击通过改变文本的表面形式来试图破坏水印，使水印难以检测。为了应对这些攻击，SIR 技术利用语义嵌入模型和精确的概率调整，增强了水印的鲁棒性，确保水印在文本被重写或翻译后仍然能够被检测到。这种方法提高了水印技术在实际应用中的可靠性和有效性。

好的，让我们更详细地解释为什么训练 \(\Delta\) 函数使得每个词汇的 \(\Delta_i\) 接近 +1 或 -1 会增强水印的鲁棒性。

### 1. 词汇的 \(\Delta_i\) 值的意义

\(\Delta_i\) 的值代表了对每个词汇 \(v_i\) 的调整程度：

- \(\Delta_i \approx +1\)：表示这个词汇是一个绿色令牌（green token），在生成过程中增加其出现的概率。
- \(\Delta_i \approx -1\)：表示这个词汇是一个红色令牌（red token），在生成过程中减少其出现的概率。

### 2. 增加与减少词汇出现概率的作用

通过训练 \(\Delta\) 函数使得 \(\Delta_i\) 值接近 +1 或 -1，可以有以下几个效果：

#### 增强水印嵌入的显著性

- **绿色令牌（\(\Delta_i \approx +1\)）**：
  - 增加绿色令牌的出现概率，使这些词汇在生成文本中更加频繁地出现。这有助于在生成的文本中嵌入显著的水印信号。
  - 例如，如果“苹果”是绿色令牌，在文本生成时“苹果”出现的概率会比未调整前高。

- **红色令牌（\(\Delta_i \approx -1\)）**：
  - 减少红色令牌的出现概率，使这些词汇在生成文本中不常出现。这有助于减少噪声，提高水印信号的对比度。
  - 例如，如果“香蕉”是红色令牌，在文本生成时“香蕉”出现的概率会比未调整前低。

#### 增强水印的鲁棒性

通过这种方式调整词汇的出现概率，可以在以下几个方面增强水印的鲁棒性：

- **对重写攻击的鲁棒性**：
  - 在重写过程中，虽然词汇和句子结构可能会变化，但由于水印嵌入的显著性增强，原本频繁出现的绿色令牌即使被替换或改变，其模式仍能保持一定的特点，使得水印仍然可检测。
  - 例如，如果“苹果”频繁出现，重写后变为“水果”，其频繁出现的模式仍然可以被检测。

- **对翻译攻击的鲁棒性**：
  - 翻译过程中，词汇可能会被替换为其同义词或其他翻译结果，但由于 \(\Delta_i\) 值接近 +1 或 -1，使得调整后的概率分布模式在翻译后的文本中仍能保持。
  - 例如，“苹果”翻译为“apple”，再翻译回中文可能变为“水果”，但其出现频率的调整模式在嵌入空间中仍然保留了一定的特点。

### 3. 具体示例

**原始文本**：
```
我喜欢吃苹果。
```

**通过 \(\Delta\) 函数调整后的文本**：
```
我非常喜欢吃苹果。
```
假设“喜欢”和“苹果”是绿色令牌（\(\Delta_i \approx +1\)），在生成过程中增加它们的出现概率。

**改写后的文本**：
```
我特别喜欢吃水果。
```
尽管“苹果”被改写为“水果”，“喜欢”的高频出现模式仍然保留了一定的特点。

**翻译后的文本**：
原文：`I like eating apples.`
翻译后：`我喜欢吃苹果。`
尽管通过不同语言之间的翻译，文本表面形式发生了变化，但“喜欢”和“苹果”的出现频率模式仍然保留。

### 4. 数学解释

训练 \(\Delta\) 函数的目标是最小化以下损失函数：
\[
\mathcal{L} = |\text{Sim}(E(\mathbf{x}), E(\mathbf{y})) - \text{Sim}(\Delta(\mathbf{x}), \Delta(\mathbf{y}))|
\]
这确保了调整后的文本对在嵌入空间中的相似度接近原始文本对的相似度，从而在语义层面保持了一致性。

### 总结

训练 \(\Delta\) 函数使得每个词汇的 \(\Delta_i\) 接近 +1 或 -1，通过增加绿色令牌的出现概率和减少红色令牌的出现概率，可以显著增强水印的嵌入效果和鲁棒性。即使文本经过重写或翻译，调整后的概率分布模式在嵌入空间中仍然保持一致，使得水印能够在各种攻击下仍然被检测到。

---


这个损失函数用于训练 \(\Delta\) 函数，使得调整后的文本在嵌入空间中的相似度接近原始文本对的相似度。我们详细解释其中的每一部分：

### 损失函数公式

\[
\mathcal{L} = |\text{Sim}(E(\mathbf{x}), E(\mathbf{y})) - \text{Sim}(\Delta(\mathbf{x}), \Delta(\mathbf{y}))|
\]

### 关键组成部分

1. **\(\text{Sim}(E(\mathbf{x}), E(\mathbf{y}))\)**：
   - 这是原始文本 \(\mathbf{x}\) 和 \(\mathbf{y}\) 在嵌入空间中的相似度。
   - \(E(\cdot)\) 是一个嵌入模型，它将文本映射到高维向量空间。
   - \(\text{Sim}(\cdot)\) 是一个相似度函数，常用的有余弦相似度或欧几里得距离等。

2. **\(\text{Sim}(\Delta(\mathbf{x}), \Delta(\mathbf{y}))\)**：
   - 这是经过 \(\Delta\) 函数调整后的文本 \(\Delta(\mathbf{x})\) 和 \(\Delta(\mathbf{y})\) 在嵌入空间中的相似度。
   - \(\Delta(\cdot)\) 是我们要训练的函数，用于调整文本中的词汇以嵌入水印。

3. **损失函数 \(\mathcal{L}\)**：
   - 损失函数的目标是最小化原始文本对和调整后文本对的相似度差异。
   - 损失函数的形式是两个相似度的绝对差值的绝对值。

### 详细解释

#### 嵌入模型 \(E(\cdot)\)

嵌入模型将文本中的词汇映射到高维向量空间，使得具有相似语义的词汇在这个空间中的距离较近。例如，词汇“苹果”和“橙子”在嵌入空间中会非常接近，因为它们都是水果。

#### 相似度函数 \(\text{Sim}(\cdot)\)

相似度函数用于衡量两个嵌入向量之间的相似度。例如：

- **余弦相似度**：衡量两个向量之间的夹角，值域为 [-1, 1]，1 表示完全相同，-1 表示完全相反。
- **欧几里得距离**：衡量两个向量之间的直线距离，值越小表示越相似。

#### \(\Delta\) 函数的作用

\(\Delta\) 函数用于调整文本中的词汇，使得调整后的文本保留原始文本的语义相似度，同时嵌入水印。通过训练 \(\Delta\) 函数，我们希望调整后的文本对 \(\Delta(\mathbf{x})\) 和 \(\Delta(\mathbf{y})\) 在嵌入空间中的相似度接近原始文本对 \(E(\mathbf{x})\) 和 \(E(\mathbf{y})\) 的相似度。

### 损失函数的目标

损失函数的目标是最小化原始文本对和调整后文本对的相似度差异。具体目标如下：

- **保持语义一致性**：通过使调整后的文本对 \(\Delta(\mathbf{x})\) 和 \(\Delta(\mathbf{y})\) 的相似度接近原始文本对 \(E(\mathbf{x})\) 和 \(E(\mathbf{y})\) 的相似度，我们确保了语义的一致性。
- **增强水印鲁棒性**：通过调整文本中的词汇，嵌入水印信息，使得即使文本被重写或翻译，水印仍能保留并被检测到。

### 举例说明

假设有两个原始文本对 \(\mathbf{x}\) 和 \(\mathbf{y}\)：

- \(\mathbf{x}\)：`The cat sits on the mat.`
- \(\mathbf{y}\)：`The feline rests on the rug.`

它们在嵌入空间中的相似度可能较高，因为“cat” 和 “feline” 以及 “mat” 和 “rug” 是语义相近的词汇。

现在我们通过 \(\Delta\) 函数调整这两个文本：

- \(\Delta(\mathbf{x})\)：`The cat sits on the mat.`（可能保持不变）
- \(\Delta(\mathbf{y})\)：`The feline rests on the rug.`（可能增加了一些水印信息）

我们希望 \(\Delta(\mathbf{x})\) 和 \(\Delta(\mathbf{y})\) 在嵌入空间中的相似度尽可能接近 \(E(\mathbf{x})\) 和 \(E(\mathbf{y})\) 的相似度。

### 训练过程

通过不断调整 \(\Delta\) 函数的参数，使得损失函数 \(\mathcal{L}\) 逐渐减小，从而达到最小化原始文本对和调整后文本对的相似度差异的目标。这确保了调整后的文本不仅包含水印信息，而且在语义上与原始文本一致。

### 总结

这个损失函数通过最小化原始文本对和调整后文本对的相似度差异，确保调整后的文本在嵌入空间中的语义相似度接近原始文本，从而实现水印的嵌入和检测，同时保持文本的语义一致性。这种方法增强了水印技术的鲁棒性，使其在面对重写和翻译攻击时依然有效。


![Alt text](assets/watermark/image-9.png)
这张图描述了评估文本水印在跨语言环境中的一致性的方法。具体来说，它介绍了如何通过 Pearson 相关系数（PCC）和相对误差（RE）来衡量水印在被翻译后的效果。以下是详细解释：

### 评估跨语言一致性

跨语言一致性（cross-lingual consistency）评估的是文本水印在被翻译成其他语言后，保持其有效性的能力。具体衡量标准包括：

1. **趋势一致性（trend consistency）**：
   - 通过 Pearson 相关系数（PCC）来衡量。
   
2. **幅度一致性（magnitude consistency）**：
   - 通过相对误差（RE）来衡量。

### 具体指标解释

#### Pearson 相关系数（PCC）

Pearson 相关系数用于衡量两个变量之间的线性关系。其公式为：

\[
\text{PCC}(S, \hat{S}) = \frac{\text{cov}(S, \hat{S})}{\sigma_S \sigma_{\hat{S}}}
\]

- **S**：原始水印强度。
- **\(\hat{S}\)**：翻译后的水印强度。
- **\(\text{cov}(S, \hat{S})\)**：S 和 \(\hat{S}\) 之间的协方差。
- **\(\sigma_S\)** 和 **\(\sigma_{\hat{S}}\)**：S 和 \(\hat{S}\) 的标准差。

PCC 值的范围为 [-1, 1]，其中：
- 1 表示完全正相关。
- -1 表示完全负相关。
- 0 表示没有线性相关。

**示例**：

假设我们有以下原始和翻译后的水印强度：

- **原始水印强度 \(S\)**：\[1.2, 2.3, 3.4, 4.5, 5.6\]
- **翻译后水印强度 \(\hat{S}\)**：\[1.1, 2.4, 3.3, 4.6, 5.5\]

计算 PCC：

1. 计算 S 和 \(\hat{S}\) 的平均值。
2. 计算 S 和 \(\hat{S}\) 的标准差。
3. 计算 S 和 \(\hat{S}\) 的协方差。
4. 使用公式计算 PCC。

如果 PCC 接近 1，说明翻译前后水印强度的趋势保持一致。

#### 相对误差（RE）

相对误差用于衡量翻译前后水印强度的幅度一致性。其公式为：

\[
\text{RE}(S, \hat{S}) = \mathbb{E} \left[ \frac{|\hat{S} - S|}{|S|} \right] \times 100\%
\]

- **S**：原始水印强度。
- **\(\hat{S}\)**：翻译后的水印强度。
- **\(\mathbb{E}\)**：期望值。

RE 值表示翻译前后水印强度的相对误差，以百分比形式表示。

**示例**：

假设我们有以下原始和翻译后的水印强度：

- **原始水印强度 \(S\)**：\[1.2, 2.3, 3.4, 4.5, 5.6\]
- **翻译后水印强度 \(\hat{S}\)**：\[1.1, 2.4, 3.3, 4.6, 5.5\]

计算 RE：

1. 计算每对 \(S\) 和 \(\hat{S}\) 的绝对误差并除以原始水印强度 \(S\)。
2. 计算这些比值的平均值。
3. 乘以 100% 得到 RE 值。

如果 RE 值较小，说明翻译前后水印强度的幅度变化不大，即幅度一致性较好。

### 具体流程

1. **定义跨语言一致性**：
   - 衡量文本水印在被翻译成其他语言后保持其有效性的能力。

2. **给定原始水印强度 S 和翻译后的水印强度 \(\hat{S}\)**：
   - 通过 PCC 衡量趋势一致性。
   - 通过 RE 衡量幅度一致性。

### 总结

通过 Pearson 相关系数（PCC）和相对误差（RE），可以分别从趋势和幅度两个方面评估文本水印在跨语言环境中的一致性。这两个指标提供了一种系统的方法来衡量水印在被翻译后的有效性，从而确保水印技术在多语言应用中的鲁棒性和可靠性。

![Alt text](assets/watermark/image-10.png)

这张图表展示了不同文本水印方法在跨语言一致性评估中的表现。具体来说，图表对比了三种水印方法（KGW、UW 和 SIR）在不同语言对之间的 Pearson 相关系数（PCC）和相对误差（RE）的表现。以下是详细解释：

### 图表结构

- **Method**: 水印方法，包括 KGW（Kuleshov, Ganchev, and Weiss）、UW（Unigram Watermarking）和 SIR（Semantic Invariant Robust Watermarking）。
- **Language Pairs**: 不同的语言对，例如 En→Zh（英语到中文）、En→Ja（英语到日语）等。
- **PCC (↑)**: Pearson 相关系数，用于衡量趋势一致性。值越高，表示一致性越好。
- **RE (%) (↓)**: 相对误差，用于衡量幅度一致性。值越低，表示一致性越好。

### 数据解释

#### 上半部分：Baichuan-7B 模型

- **PCC**:
  - KGW 方法在不同语言对上的 PCC 值在 -0.257 到 0.144 之间，平均值为 0.013。
  - UW 方法的 PCC 值在 0.087 到 0.183 之间，平均值为 0.156。
  - SIR 方法的 PCC 值在 0.234 到 0.380 之间，平均值为 0.311，是三种方法中最高的，显示出较好的趋势一致性。

- **RE (%)**:
  - KGW 方法在不同语言对上的 RE 值在 73.65% 到 88.50% 之间，平均值为 78.54%。
  - UW 方法的 RE 值在 97.57% 到 98.82% 之间，平均值为 97.88%，是三种方法中最高的，显示出较差的幅度一致性。
  - SIR 方法的 RE 值在 68.28% 到 93.41% 之间，平均值为 80.41%，显示出较好的幅度一致性。

#### 下半部分：Llama-2-7B-chat 模型

- **PCC**:
  - KGW 方法在不同语言对上的 PCC 值在 -0.106 到 0.323 之间，平均值为 0.051。
  - UW 方法的 PCC 值在 0.076 到 0.116 之间，平均值为 0.098。
  - SIR 方法的 PCC 值在 0.146 到 0.323 之间，平均值为 0.051，是三种方法中最高的，显示出较好的趋势一致性。

- **RE (%)**:
  - KGW 方法在不同语言对上的 RE 值在 68.57% 到 92.54% 之间，平均值为 86.06%。
  - UW 方法的 RE 值在 94.93% 到 96.14% 之间，平均值为 94.93%，是三种方法中最高的，显示出较差的幅度一致性。
  - SIR 方法的 RE 值在 59.76% 到 92.80% 之间，平均值为 72.48%，显示出较好的幅度一致性。

### 关键观察

1. **PCCs**:
   - PCC 值通常小于 0.2，表明趋势一致性在所有方法中都不是很强。
   - SIR 方法的 PCC 值总体上略高于其他方法，显示出其在趋势一致性方面的优势。

2. **REs**:
   - RE 值通常高于 80%，表明幅度一致性在所有方法中普遍较弱。
   - SIR 方法的 RE 值略低于其他方法，显示出其在幅度一致性方面的优势。

3. **综合表现**:
   - SIR 方法在大多数语言对和模型上表现出更好的趋势一致性和幅度一致性，略优于 KGW 和 UW 方法。
   - KGW 方法在 RE 方面表现较好，但在 PCC 方面较弱。
   - UW 方法在 PCC 和 RE 方面均表现较差。

### 具体解释

**示例**：

对于 Baichuan-7B 模型：
- 在 En→Zh（英语到中文）的语言对上，SIR 方法的 PCC 为 0.283，RE 为 68.28%，这意味着 SIR 方法在这个语言对上保持了较好的趋势和幅度一致性。
- 相比之下，KGW 方法的 PCC 为 0.108，RE 为 75.62%，而 UW 方法的 PCC 为 0.190，RE 为 97.57%，显示出 SIR 方法在这个语言对上的优势。

对于 Llama-2-7B-chat 模型：
- 在 En→Ja（英语到日语）的语言对上，SIR 方法的 PCC 为 -0.106，RE 为 92.80%，这虽然显示了 SIR 方法在趋势一致性上的挑战，但在幅度一致性上仍然优于 UW 方法（PCC 为 0.092，RE 为 95.40%）。

### 总结

通过分析不同水印方法在跨语言一致性评估中的表现，我们可以看出 SIR 方法在保持趋势一致性和幅度一致性方面略优于其他方法。这表明 SIR 方法在面对跨语言翻译和重写攻击时具有更好的鲁棒性和有效性。

![Alt text](assets/watermark/image-11.png)
这张图展示了文本长度与水印强度之间的关系，比较了三种不同的文本水印方法（KGW、UW 和 SIR）在原始语言和翻译后的语言下的表现。图中包含三个子图，分别对应三种水印方法，横轴表示文本长度，纵轴表示水印强度。具体解释如下：

### 图表概述

- **横轴（Text Length）**：表示文本的长度，范围从 25 到 525。
- **纵轴（Watermark Strength）**：表示水印的强度，根据不同方法的计算公式不同。
- **颜色和符号**：不同颜色和符号代表不同的语言对，例如：
  - 红色三角形（En，Original language）：原始英语文本。
  - 蓝色三角形（En→Zh）：英语到中文的翻译。
  - 绿色圆圈（En→Ja）：英语到日语的翻译。
  - 橙色正方形（En→Fr）：英语到法语的翻译。
  - 紫色菱形（En→De）：英语到德语的翻译。

### 子图 (a): KGW 方法

- **原始语言（红色三角形）**：水印强度随文本长度增加而显著增加，显示出较高的水印强度。
- **翻译后的语言**：水印强度保持较低且稳定，几乎不随文本长度变化。这表明 KGW 方法在翻译后失去了大部分水印强度。

### 子图 (b): UW 方法

- **原始语言（红色三角形）**：水印强度随文本长度增加而显著增加，显示出较高的水印强度。
- **翻译后的语言**：水印强度保持较低且稳定，几乎不随文本长度变化。这与 KGW 方法类似，表明 UW 方法在翻译后也失去了大部分水印强度。

### 子图 (c): SIR 方法

- **原始语言（红色三角形）**：水印强度随文本长度增加而显著增加，显示出较高的水印强度。
- **翻译后的语言**：水印强度保持较低，但相比 KGW 和 UW 方法有更好的保持趋势，随文本长度略有增加。

### 关键观察

1. **跨语言一致性**：
   - KGW 和 UW 方法在翻译后的水印强度显著降低，几乎没有随着文本长度变化，显示出较差的跨语言一致性。
   - SIR 方法在翻译后的水印强度保持相对较好，显示出更好的跨语言一致性。

2. **水印强度与文本长度的关系**：
   - 在原始语言中，所有方法的水印强度都随文本长度显著增加。
   - 在翻译后的语言中，SIR 方法的水印强度随文本长度略有增加，而 KGW 和 UW 方法则几乎没有变化。

### 具体解释

假设我们有一个初始的英语文本，随着文本长度从 25 增加到 525，水印强度变化如下：

1. **在原始语言中**：
   - KGW 方法和 UW 方法的水印强度随着文本长度显著增加，例如从 2 增加到 10。
   - SIR 方法的水印强度也随着文本长度增加，但增加的幅度较小，例如从 0.1 增加到 0.35。

2. **在翻译后的语言中**：
   - KGW 和 UW 方法的水印强度保持在低水平，不随文本长度变化，例如保持在 1 以下。
   - SIR 方法的水印强度略有增加，例如从 0.1 增加到 0.2，显示出较好的保持趋势。

### 总结

这张图表明，当前的文本水印方法在跨语言一致性方面表现不佳，尤其是 KGW 和 UW 方法在翻译后失去了大部分水印强度。而 SIR 方法在翻译后的水印强度保持相对较好，显示出更好的跨语言一致性。这意味着 SIR 方法在面对不同语言的翻译时，能更有效地保持水印信息，提高了水印技术的鲁棒性和实用性。


![Alt text](assets/watermark/image-12.png)
这张图包含了关于语言切换和文本质量的两点重要说明。以下是详细解释：

### 语言切换 (Language Switching)

**说明**：攻击者如果想移除水印，通常不希望改变响应文本的语言。

**详细解释**：
- **背景**：水印技术用于在文本中嵌入一些不可见的信息，以验证文本的真实性或来源。攻击者可能会尝试通过各种方法来移除这些水印。
- **语言切换的挑战**：
  - **保持语言一致性**：攻击者通常不希望通过改变文本的语言来移除水印，因为这会明显改变文本的内容和用途。例如，如果原始文本是英文，攻击者可能不希望将其转换为中文来移除水印。
  - **影响检测能力**：语言切换会使得水印检测变得复杂，因为不同语言之间的转换可能会改变文本的语义和结构，从而影响水印的检测能力。

**示例**：
- **不希望语言切换**：如果一个攻击者试图移除一篇英文文章中的水印，他们可能会尝试通过同义词替换或句子结构重写来实现，而不会将文章翻译成另一种语言如西班牙语。这是因为翻译不仅会改变文章的语言，还会引入其他翻译错误和风格变化，影响文章的原始意图和读者的理解。

### 文本质量 (Text Quality)

**说明**：翻译可能会影响文本质量，但在前面的章节中我们没有对这一点进行评估，因为我们在响应中更改了语言。

**详细解释**：
- **背景**：翻译过程会不可避免地影响文本的质量，可能会引入翻译错误、语法问题或风格变化。
- **文本质量的影响**：
  - **准确性**：翻译后的文本可能不完全准确，某些细微的语义或上下文可能会丢失或改变。
  - **可读性**：翻译后的文本可能会显得不那么自然或流畅，尤其是当自动翻译工具用于处理复杂或长篇文本时。
  - **风格一致性**：不同语言之间的翻译可能会导致风格和语气的变化，使得文本在目标语言中的表达与原始语言不同。

**示例**：
- **质量下降的风险**：例如，一段包含技术术语和专有名词的英文文本在翻译成日文时，可能会出现术语翻译不准确、句子结构不自然等问题，导致文本质量下降。

### 总结

- **语言切换**：攻击者通常不会通过改变文本的语言来移除水印，因为这会显著改变文本的内容和用途，影响文本的连贯性和可读性。
- **文本质量**：翻译过程可能会影响文本的质量，包括准确性、可读性和风格一致性，但在前面的章节中并没有对这一点进行评估，因为重点在于更改语言后的水印保持情况。

这两点说明强调了在研究文本水印技术时需要考虑的实际问题，包括如何在保持文本自然性和质量的同时，增强水印的鲁棒性和检测能力。

![Alt text](assets/watermark/image-13.png)
这张图片描述了跨语言水印移除攻击（Cross-lingual Watermark Removal Attack，CWRA）的流程。以下是详细解释：

### 图中各部分的内容

1. **Original Prompt (En)**：
   - 原始提示词是英语 (En)。
   - 示例文本：“The powerful generative capabilities of language models pose risks, such as...”
   - 这是初始输入的文本。

2. **Translation System**：
   - 将原始提示词翻译成中文 (Zh)。
   - 这是攻击的第一步，通过将文本从原始语言翻译成枢轴语言。

3. **Pivot Prompt (Zh)**：
   - 翻译后的中文提示词 (Zh)。
   - 示例文本：“语言模型强大的生成能力带来了风险，例如...”
   - 这是中间步骤，用于进一步生成响应。

4. **LLMs (Large Language Models)**：
   - 使用大语言模型生成响应。
   - 这些模型处理中文提示词并生成相应的中文响应。

5. **Watermark Algorithms**：
   - 在生成的中文响应中应用水印算法。
   - 这些算法嵌入水印信息，以便后续检测。

6. **Pivot Response (Zh)**：
   - 生成的中文响应，带有水印。
   - 示例文本：“虚假新闻的传播和在学术写作中的作弊行为，无论内容是什么语言。”
   - 这是大语言模型生成的带有水印的响应。

7. **Translation System**：
   - 将带有水印的中文响应再翻译回英语 (En)。
   - 这是攻击的第二步，通过将带有水印的文本从枢轴语言翻译回原始语言。

8. **Response (En)**：
   - 最终的英语响应，带有水印。
   - 示例文本：“the spread of fake news and the misuse for cheating in academic writing, regardless of the language of the content.”
   - 这是经过两次翻译和处理后的最终输出。

### 核心思想

- **核心目标**：攻击者不仅希望移除水印，还希望在原始语言中获得高质量的响应。其核心思想是将查询转换为枢轴语言进行处理，以达到绕过水印检测的目的。

### 详细流程解释

1. **初始输入**：
   - 用户在原始语言（英语）中输入一个提示词。
   - 示例输入为：“The powerful generative capabilities of language models pose risks, such as...”

2. **第一次翻译**：
   - 输入的提示词通过翻译系统被翻译成枢轴语言（中文）。
   - 翻译后的提示词为：“语言模型强大的生成能力带来了风险，例如...”

3. **生成响应**：
   - 大语言模型接收翻译后的提示词并生成响应。
   - 生成的响应为：“虚假新闻的传播和在学术写作中的作弊行为，无论内容是什么语言。”

4. **水印嵌入**：
   - 在生成的中文响应中嵌入水印，确保后续可以检测到文本的生成来源。
   - 生成的响应带有水印信息。

5. **第二次翻译**：
   - 带有水印的中文响应通过翻译系统被翻译回原始语言（英语）。
   - 翻译后的响应为：“the spread of fake news and the misuse for cheating in academic writing, regardless of the language of the content.”

6. **最终输出**：
   - 攻击者获得的最终输出是带有水印的英语响应。

### 为什么攻击者使用这种方法

1. **规避检测**：
   - 通过将文本从一种语言翻译到另一种语言，攻击者试图绕过直接的水印检测。
   - 翻译过程可能会改变文本的某些特性，使得水印检测变得更加困难。

2. **保持响应质量**：
   - 直接在原始语言中生成高质量的响应，同时移除水印是困难的。
   - 通过枢轴语言的转换，攻击者可以在保持高质量响应的同时，实现水印的移除或弱化。

### 总结

这张图描述了跨语言水印移除攻击的过程，展示了攻击者如何利用语言转换和大语言模型生成响应，同时嵌入和移除水印。这种方法旨在规避水印检测，保持生成文本的高质量和自然性，同时实现攻击目的。


在跨语言水印移除攻击（CWRA）的过程中，确实有一个步骤是将文本翻译成另一种语言，再将其翻译回来。你的问题是为什么还要在中间步骤中添加水印，而不是直接通过翻译来移除水印。这是一个很好的问题，以下是详细解释：

### 为什么中间要使用水印算法添加水印

1. **验证水印移除效果**：
   - 中间步骤中添加水印是为了验证跨语言翻译过程是否有效地移除了原始的水印。
   - 如果没有中间的水印添加步骤，无法验证翻译过程对水印的移除效果。

2. **检测水印的鲁棒性**：
   - 添加水印可以测试不同水印方法的鲁棒性，评估它们在不同攻击下的表现。
   - 通过对比添加水印前后的检测效果，可以评估水印算法的有效性和抗攻击能力。

3. **多层次的水印保护**：
   - 在实际应用中，文本可能会经历多次处理和转换，只有一种水印可能不足以提供全面保护。
   - 通过在不同步骤中添加水印，可以提供多层次的保护，增强水印的鲁棒性。

4. **确保实验一致性**：
   - 为了在研究和实验中保持一致性，通常会使用标准化的水印添加和检测过程。
   - 中间步骤中添加水印确保了实验结果的可重复性和可验证性。

### 直接翻译不一定能消除水印

虽然跨语言翻译可以在一定程度上削弱或改变水印，但并不能保证完全移除所有水印。以下是一些原因：

1. **水印的多样性**：
   - 不同的水印算法使用不同的技术嵌入水印，有些可能对翻译更为敏感，有些则不然。
   - 直接翻译可能不足以移除所有类型的水印。

2. **语言结构差异**：
   - 不同语言之间的结构差异可能会保留一些水印信息，即使翻译回原始语言，某些特征仍可能存在。
   - 水印算法设计的一个目标是尽量使水印在不同语言之间具有一定的鲁棒性。

3. **文本内容和风格的保留**：
   - 翻译过程可能会保留一些原始文本的内容和风格，使得水印在某种程度上仍然存在。
   - 这意味着仅通过翻译可能无法完全移除水印，特别是那些嵌入在语义层面的水印。

### 实验目的

在CWRA实验中，添加水印的目的是为了：

- **评估不同水印算法在翻译过程中的表现**。
- **验证水印在跨语言转换中的鲁棒性**。
- **确保实验结果的一致性和可验证性**。

通过添加水印，可以准确测量和比较不同水印算法在各种攻击下的性能，包括重翻译、重写和CWRA。

### 结论

虽然跨语言翻译可以在一定程度上削弱水印，但为了全面评估水印算法的鲁棒性和有效性，在CWRA实验中需要在中间步骤中添加水印。这确保了实验的一致性、可重复性，并提供了多层次的保护和检测机制。直接翻译虽然可能移除部分水印，但无法保证所有类型的水印都能被完全移除，因此需要结合水印添加和检测过程进行全面评估。

![Alt text](assets/watermark/image-14.png)
这张图展示了不同水印方法（KGW、UW、SIR）在多种攻击方法（重翻译、重写和跨语言水印移除攻击CWRA）下的ROC曲线。ROC曲线用于评估分类模型的性能，横轴是假阳性率（False Positive Rate, FPR），纵轴是真阳性率（True Positive Rate, TPR）。以下是详细解释：

### 图表结构

1. **子图 (a): KGW 方法**
   - **攻击方法**：
     - No attack：没有攻击，显示了最理想的情况。
     - Re-translation：重翻译攻击。
     - Paraphrase：重写攻击。
     - CWRA (Ours)：跨语言水印移除攻击。
     - Random：随机基线，用于对比。
   - **TPR 值**：在固定的 FPR = 0.1 下，TPR 分别为 0.992（没有攻击），0.776（重翻译），0.594（重写），0.213（CWRA）。

2. **子图 (b): UW 方法**
   - **攻击方法**：
     - No attack：没有攻击。
     - Re-translation：重翻译攻击。
     - Paraphrase：重写攻击。
     - CWRA (Ours)：跨语言水印移除攻击。
     - Random：随机基线。
   - **TPR 值**：在固定的 FPR = 0.1 下，TPR 分别为 0.913（没有攻击），0.263（重翻译），0.238（重写），0.166（CWRA）。

3. **子图 (c): SIR 方法**
   - **攻击方法**：
     - No attack：没有攻击。
     - Re-translation：重翻译攻击。
     - Paraphrase：重写攻击。
     - CWRA (Ours)：跨语言水印移除攻击。
     - Random：随机基线。
   - **TPR 值**：在固定的 FPR = 0.1 下，TPR 分别为 0.940（没有攻击），0.825（重翻译），0.682（重写），0.230（CWRA）。

### 详细解释

#### 1. KGW 方法 (a)

- **没有攻击**：KGW 方法在没有攻击的情况下，表现出极高的真阳性率（0.992），几乎能够完美检测到水印。
- **重翻译攻击**：重翻译攻击显著降低了TPR至0.776，但依然保持在较高水平。
- **重写攻击**：重写攻击进一步降低了TPR至0.594。
- **CWRA**：跨语言水印移除攻击将TPR降至0.213，表明这种攻击方法在移除KGW水印方面较为有效。

#### 2. UW 方法 (b)

- **没有攻击**：在没有攻击的情况下，UW 方法的TPR为0.913，高于随机基线，显示出较好的水印检测能力。
- **重翻译攻击**：重翻译攻击将TPR显著降低至0.263。
- **重写攻击**：重写攻击的效果类似，TPR为0.238。
- **CWRA**：CWRA将TPR降至0.166，表明这种攻击方法对UW水印的移除效果明显。

#### 3. SIR 方法 (c)

- **没有攻击**：在没有攻击的情况下，SIR 方法的TPR为0.940，显示出极高的水印检测能力。
- **重翻译攻击**：重翻译攻击将TPR降至0.825，虽然有所降低，但依然较高。
- **重写攻击**：重写攻击进一步降低TPR至0.682。
- **CWRA**：CWRA将TPR降至0.230，显示出一定的攻击效果，但相对KGW和UW方法，SIR方法的鲁棒性更强。

### 关键观察

1. **无攻击条件下的性能**：所有方法在无攻击条件下均表现出高水平的TPR，表明水印检测机制在正常情况下非常有效。
2. **攻击方法的影响**：
   - 重翻译和重写攻击均显著降低了TPR，显示出这些方法在一定程度上能够破坏水印的检测。
   - CWRA 攻击的影响更为显著，尤其是对KGW和UW方法，其TPR大幅下降，表明这种方法在移除水印方面更有效。
3. **SIR 方法的鲁棒性**：相比之下，SIR方法在面对不同攻击时表现出更好的鲁棒性，特别是在CWRA攻击下，尽管TPR有所下降，但依然高于KGW和UW方法。

### 总结

这张图表明了不同水印方法在各种攻击下的检测性能。CWRA攻击对所有方法的影响最显著，但SIR方法展示出更强的鲁棒性，能够更好地抵御水印移除攻击。这表明SIR方法在跨语言和重写攻击下更为有效，是一种更为鲁棒的水印技术。

![Alt text](assets/watermark/image-15.png)
这张图展示了不同水印移除攻击方法对文本质量的影响比较，分为文本摘要（Text Summarization）和问答（Question Answering）两部分。表格使用了ROUGE（Recall-Oriented Understudy for Gisting Evaluation）指标来评估文本质量，包括ROUGE-1、ROUGE-2和ROUGE-L分数。以下是详细解释：

### 表格结构

表格按水印移除方法（KGW、UW、SIR）和攻击类型（No attack、Re-translation、Paraphrase、CWRA）进行了比较。

### ROUGE 指标

- **ROUGE-1**：单词级别的匹配。
- **ROUGE-2**：二元组（bigram）级别的匹配。
- **ROUGE-L**：最长公共子序列（Longest Common Subsequence）。

### 关键观察

1. **CWRA 的效果**：
   - 在所有方法中，CWRA 攻击后的 ROUGE 分数普遍较高，表明在这种攻击下，文本质量得到了较好的保留。
   - 尤其是在 KGW 方法下，CWRA 攻击后的 ROUGE 分数显著高于其他攻击方法，显示了 CWRA 在文本质量保留方面的优势。

2. **不同攻击方法的影响**：
   - 无论是重翻译还是重写攻击，都对文本质量有一定影响，但影响程度各有不同。
   - 在大多数情况下，CWRA 方法表现出更好的文本质量，这可能归因于高质量的翻译和重写技术。

3. **文本摘要和问答的对比**：
   - 在文本摘要任务中，所有方法的 ROUGE 分数总体较高，CWRA 方法的优势更为明显。
   - 在问答任务中，不同方法的 ROUGE 分数差异较小，但 CWRA 依然表现出较好的鲁棒性和文本质量保留能力。

### 总结

这张表展示了不同水印移除攻击方法对文本质量的影响比较，使用 ROUGE 指标评估文本摘要和问答任务。CWRA 方法在大多数情况下表现出最佳的文本质量保留能力，尤其是在 KGW 方法下，其 ROUGE 分数显著高于其他方法。这表明 CWRA 在水印移除和文本质量保留方面具有优势。


---

ROUGE（Recall-Oriented Understudy for Gisting Evaluation）是用于自动摘要和机器翻译等自然语言处理任务的评价指标。以下是ROUGE指标的详细解释：

1. **ROUGE-1**（单词级别的匹配）：
   - **定义**：ROUGE-1度量的是生成文本与参考文本之间的单词重叠情况。它关注单个单词的匹配。
   - **计算方式**：计算生成文本中与参考文本中相同的单词的数量，并用这些单词的数量来计算精确度（Precision）、召回率（Recall）和F1分数。
   - **示例**：如果参考文本是“机器学习在许多领域都有应用”，而生成文本是“机器学习广泛应用于许多领域”，那么“机器”，“学习”，“领域”，“应用”这些单词在两者之间都有出现，ROUGE-1的得分会较高。

2. **ROUGE-2**（二元组（bigram）级别的匹配）：
   - **定义**：ROUGE-2度量的是生成文本与参考文本之间的二元组（即连续两个单词）的重叠情况。
   - **计算方式**：计算生成文本中与参考文本中的二元组的匹配情况，并用这些二元组的数量来计算精确度、召回率和F1分数。
   - **示例**：如果参考文本是“机器学习在许多领域都有应用”，而生成文本是“机器学习广泛应用于许多领域”，那么二元组如“机器 学习”，“学习 在”，“在 许多”等在两者之间都有出现，ROUGE-2的得分会较高。

3. **ROUGE-L**（最长公共子序列）：
   - **定义**：ROUGE-L度量的是生成文本与参考文本之间的最长公共子序列（LCS）。LCS是一种在两个序列中，按顺序出现的最大子序列。
   - **计算方式**：计算生成文本中与参考文本中的最长公共子序列的匹配情况，并用这些匹配的子序列来计算精确度、召回率和F1分数。
   - **示例**：如果参考文本是“机器学习在许多领域都有应用”，而生成文本是“机器学习领域的应用非常广泛”，最长公共子序列可能是“机器 学习 领域 应用”，ROUGE-L的得分会根据这个最长公共子序列的匹配情况来计算。

这三个ROUGE指标可以综合评估生成文本与参考文本的质量，ROUGE-1主要关注单个单词的匹配，ROUGE-2关注二元组的匹配，ROUGE-L关注最长公共子序列。

---

水印强度是衡量文本中隐藏水印的强度或显著性的一种度量。在数字水印技术中，水印是嵌入在原始内容中的信息，通常难以被察觉，但能够在需要时提取出来以证明内容的真实性或版权。水印强度的计算通常涉及统计分析，以评估嵌入的水印在原始内容中的干扰程度。

**水印强度的计算步骤：**

1. **选择特征：** 首先，确定文本中需要检测的特征。这些特征可以是文本的某些统计属性，如词频、字符频率等，这些属性可能受到水印的影响。

2. **计算水印强度指标：** 对于给定的文本，根据所选择的特征计算相应的水印强度指标。常用的指标包括：

   - **z-score**：标准分数（z-score）是一种衡量数据点与其均值之间的差异的统计方法。通过计算文本特征的z-score，可以评估水印在特定特征中的强度。z-score的计算公式是：

     \[
     z = \frac{X - \mu}{\sigma}
     \]

     其中，\( X \) 是特征值，\( \mu \) 是特征的均值，\( \sigma \) 是特征的标准差。z-score 衡量了特征值与均值的偏离程度，以标准差为单位。

   - **其他统计度量：** 可能还会使用其他统计度量，如均值、方差、标准差等，来评估水印强度。

3. **分析结果：** 根据计算的z-score或其他统计度量，分析水印的强度。z-score越大，表示水印对特征的影响越显著；z-score接近0，表示水印的影响较小或不可察觉。

4. **调整和优化：** 根据水印强度的结果，可以对水印进行调整，以确保其在内容中的隐蔽性和鲁棒性。

**总结：**

水印强度的计算主要是通过分析文本特征在水印干扰下的变化来评估水印的显著性。z-score 是一种常用的统计工具，用于量化特征值的偏离程度，以帮助检测和评估水印的强度。